{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1jD-vTh-VTwKATpDRdUl0nstAlZH70on8","authorship_tag":"ABX9TyNnmZRKB/iXW3Bd551i5IYL"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JrWA8O_KFLa9","executionInfo":{"status":"ok","timestamp":1758443728764,"user_tz":-330,"elapsed":7035,"user":{"displayName":"238w1a05e0 DASARI TEJESH","userId":"01113965708764882901"}},"outputId":"ae7aa81a-2f9a-466a-df5f-d2f48fe5e166"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: ultralytics in /usr/local/lib/python3.12/dist-packages (8.3.202)\n","Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.23.0+cu126)\n","Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.12/dist-packages (4.12.0.88)\n","Requirement already satisfied: albumentations in /usr/local/lib/python3.12/dist-packages (2.0.8)\n","Requirement already satisfied: optuna in /usr/local/lib/python3.12/dist-packages (4.5.0)\n","Requirement already satisfied: plotly in /usr/local/lib/python3.12/dist-packages (5.24.1)\n","Requirement already satisfied: seaborn in /usr/local/lib/python3.12/dist-packages (0.13.2)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (6.0.2)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (11.3.0)\n","Requirement already satisfied: pathlib2 in /usr/local/lib/python3.12/dist-packages (2.3.7.post1)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (5.9.5)\n","Requirement already satisfied: wandb in /usr/local/lib/python3.12/dist-packages (0.21.3)\n","Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (4.12.0.88)\n","Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.32.4)\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.16.1)\n","Requirement already satisfied: polars in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.25.2)\n","Requirement already satisfied: ultralytics-thop>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.0.17)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.19.1)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n","Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n","Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n","Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n","Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n","Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n","Requirement already satisfied: pydantic>=2.9.2 in /usr/local/lib/python3.12/dist-packages (from albumentations) (2.11.7)\n","Requirement already satisfied: albucore==0.0.24 in /usr/local/lib/python3.12/dist-packages (from albumentations) (0.0.24)\n","Requirement already satisfied: stringzilla>=3.10.4 in /usr/local/lib/python3.12/dist-packages (from albucore==0.0.24->albumentations) (4.0.6)\n","Requirement already satisfied: simsimd>=5.9.2 in /usr/local/lib/python3.12/dist-packages (from albucore==0.0.24->albumentations) (6.5.3)\n","Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from optuna) (1.16.5)\n","Requirement already satisfied: colorlog in /usr/local/lib/python3.12/dist-packages (from optuna) (6.9.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from optuna) (25.0)\n","Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.12/dist-packages (from optuna) (2.0.43)\n","Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.12/dist-packages (from plotly) (8.5.0)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.59.2)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.3)\n","Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from pathlib2) (1.17.0)\n","Requirement already satisfied: click>=8.0.1 in /usr/local/lib/python3.12/dist-packages (from wandb) (8.2.1)\n","Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (3.1.45)\n","Requirement already satisfied: platformdirs in /usr/local/lib/python3.12/dist-packages (from wandb) (4.4.0)\n","Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (5.29.5)\n","Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (2.37.1)\n","Requirement already satisfied: Mako in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna) (1.3.10)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.9.2->albumentations) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.9.2->albumentations) (2.33.2)\n","Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.9.2->albumentations) (0.4.1)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.4.3)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2025.8.3)\n","Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.2.4)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.2)\n","Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n"]}],"source":["!pip install ultralytics torch torchvision opencv-python-headless albumentations optuna plotly seaborn scikit-learn pandas numpy matplotlib tqdm pyyaml pillow pathlib2 psutil wandb\n"]},{"cell_type":"code","source":["# =====================================================================================\n","#         OPTIMIZED YOLO TRAINING SCRIPT (FINAL GPU VERSION)\n","# =====================================================================================\n","\n","# Standard library imports\n","import os\n","import sys\n","import yaml\n","import json\n","from pathlib import Path\n","\n","# Third-party imports\n","import cv2\n","import torch\n","import torch.nn as nn\n","from ultralytics import YOLO\n","from ultralytics.utils.loss import v8DetectionLoss\n","# ✅ FIXED: Import the correct trainer class\n","from ultralytics.models.yolo.detect.train import DetectionTrainer\n","from tqdm import tqdm\n","import matplotlib.pyplot as plt\n","\n","# =====================================================================================\n","# 🔧 1. MASTER CONFIGURATION\n","# =====================================================================================\n","\n","# ===> DATASET PATH CONFIGURATION <===\n","# 🚨 IMPORTANT: Make sure your Google Drive is mounted in Colab.\n","# These paths should point to your dataset folders within Google Drive.\n","TRAIN_DATA_ROOT = Path(\"/content/drive/MyDrive/MICROSOFT HACK/hackathon2_train_1\")\n","TEST_DATA_ROOT = Path(\"/content/drive/MyDrive/MICROSOFT HACK/Hackathon2_test1\")\n","\n","# ===> EXECUTION CONFIGURATION <===\n","# 🚀 Change the MODE here to 'train', 'predict', or 'visualize'\n","EXECUTION_CONFIG = {\n","    'MODE': 'train'  # Options: 'train', 'predict', 'visualize'\n","}\n","\n","# CLASS NAMES - 7 SAFETY OBJECTS\n","CLASS_NAMES = [\n","    'OxygenTank', 'NitrogenTank', 'FirstAidBox', 'FireAlarm',\n","    'SafetySwitchPanel', 'EmergencyPhone', 'FireExtinguisher'\n","]\n","\n","# OPTIMIZED HYPERPARAMETERS FOR T4 GPU\n","TRAINING_CONFIG = {\n","    'epochs': 50,\n","    'mosaic': 1.0,\n","    'optimizer': 'AdamW',\n","    'momentum': 0.937,\n","    'lr0': 0.01,\n","    'lrf': 0.01,\n","    'batch': 16,        # ✅ Increased batch size for GPU\n","    'imgsz': 640,\n","    'patience': 25,\n","    'warmup_epochs': 3,\n","    'weight_decay': 0.0005,\n","    'single_cls': False,\n","    'amp': True,        # ✅ Enabled Mixed Precision for T4 speedup\n","    'device': 0         # ✅ Set to use GPU\n","}\n","\n","# KNOWLEDGE DISTILLATION SETTINGS\n","KD_CONFIG = {\n","    'enable': True,\n","    'teacher_model': 'yolov8l.pt',\n","    'student_model': 'yolov8s.pt',\n","    'temperature': 4.0,\n","    'hard_weight': 0.7,\n","    'soft_weight': 0.3,\n","}\n","\n","# =====================================================================================\n","# 🧠 2. KNOWLEDGE DISTILLATION IMPLEMENTATION\n","# =====================================================================================\n","class YoloKDLoss(nn.Module):\n","    def __init__(self, student_model, hard_weight, soft_weight, temperature):\n","        super().__init__()\n","        self.hard_weight = hard_weight\n","        self.soft_weight = soft_weight\n","        self.temperature = temperature\n","        self.native_loss = v8DetectionLoss(student_model)\n","        self.kl_div = nn.KLDivLoss(reduction='batchmean')\n","\n","    def forward(self, student_preds, teacher_preds, batch):\n","        hard_loss = self.native_loss(student_preds, batch)\n","        soft_loss = 0.0\n","        if len(student_preds) > 0 and len(teacher_preds) > 0 and student_preds[-1] is not None and teacher_preds[-1] is not None:\n","            student_logits = student_preds[-1]\n","            teacher_logits = teacher_preds[-1].detach()\n","            student_soft = torch.log_softmax(student_logits / self.temperature, dim=-1)\n","            teacher_soft = torch.softmax(teacher_logits / self.temperature, dim=-1)\n","            soft_loss = self.kl_div(student_soft, teacher_soft) * (self.temperature ** 2)\n","        return self.hard_weight * hard_loss + self.soft_weight * soft_loss\n","\n","# ✅ FIXED: Inherit from DetectionTrainer instead of BaseTrainer\n","class KnowledgeDistillationTrainer(DetectionTrainer):\n","    def __init__(self, *args, **kwargs):\n","        super().__init__(*args, **kwargs)\n","        # Initialize the teacher model\n","        self.teacher = YOLO(KD_CONFIG['teacher_model']).model\n","        self.teacher.eval()\n","        for param in self.teacher.parameters():\n","            param.requires_grad = False\n","\n","    def get_loss(self, preds, batch):\n","        # Initialize loss function on the first call\n","        if not hasattr(self, 'kd_loss'):\n","            self.kd_loss = YoloKDLoss(self.model, KD_CONFIG['hard_weight'], KD_CONFIG['soft_weight'], KD_CONFIG['temperature'])\n","\n","        # Ensure teacher is on the correct device\n","        if next(self.teacher.parameters()).device != self.device:\n","            self.teacher = self.teacher.to(self.device)\n","\n","        # Get teacher predictions and calculate loss\n","        with torch.no_grad():\n","            teacher_preds = self.teacher(batch['img'])\n","        return self.kd_loss(preds, teacher_preds, batch)\n","\n","# =====================================================================================\n","# 📝 3. DATASET & UTILITY FUNCTIONS\n","# =====================================================================================\n","def create_optimized_yaml(data_path=\"yolo_params.yaml\"):\n","    train_path = TRAIN_DATA_ROOT / \"train_1\" / \"train1\" / \"images\"\n","    val_path = TRAIN_DATA_ROOT / \"train_1\" / \"val1\" / \"images\"\n","    test_path = TEST_DATA_ROOT / \"test1\" / \"images\"\n","\n","    for p in [train_path, val_path, test_path]:\n","        if not p.exists():\n","            raise FileNotFoundError(f\"The path '{p}' does not exist. Please check your DATASET PATH CONFIGURATION.\")\n","\n","    yaml_config = {\n","        'train': str(train_path.resolve()), 'val': str(val_path.resolve()), 'test': str(test_path.resolve()),\n","        'nc': len(CLASS_NAMES), 'names': CLASS_NAMES\n","    }\n","    yaml_path = Path.cwd() / data_path\n","    with open(yaml_path, 'w') as f:\n","        yaml.dump(yaml_config, f, default_flow_style=False, sort_keys=False)\n","    print(f\"✅ Dataset YAML created: {yaml_path}\")\n","    return str(yaml_path)\n","\n","# =====================================================================================\n","# 🚀 4. CORE FUNCTIONS (TRAIN, PREDICT, VISUALIZE)\n","# =====================================================================================\n","def train_enhanced_model():\n","    data_yaml = create_optimized_yaml()\n","    print(\"🚀 STARTING ENHANCED YOLO TRAINING\")\n","    print(\"-\" * 60)\n","\n","    # Unpack the dictionary into the arguments\n","    train_args = {\n","        'model': KD_CONFIG['student_model'],\n","        'data': data_yaml,\n","        'project': 'runs/detect',\n","        'name': 'enhanced_safety_detection',\n","        'exist_ok': True,\n","        'verbose': True,\n","        'plots': True,\n","        **TRAINING_CONFIG\n","    }\n","\n","    if KD_CONFIG['enable']:\n","        print(f\"🧠 Training with Knowledge Distillation...\")\n","        trainer = KnowledgeDistillationTrainer(overrides=train_args)\n","        trainer.train()\n","    else:\n","        print(\"💪 Starting Standard Training...\")\n","        model = YOLO(KD_CONFIG['student_model'])\n","        model.train(**train_args)\n","    print(\"✅ Training complete!\")\n","\n","def run_enhanced_prediction():\n","    print(\"🔍 STARTING PREDICTION & EVALUATION\")\n","    print(\"-\" * 60)\n","    yaml_path = Path.cwd() / 'yolo_params.yaml'\n","    if not yaml_path.exists():\n","        raise FileNotFoundError(\"yolo_params.yaml not found. Please run training first.\")\n","    with open(yaml_path, 'r') as file:\n","        data = yaml.safe_load(file)\n","    images_dir = Path(data['test'])\n","\n","    runs_dir = Path.cwd() / \"runs\" / \"detect\"\n","    latest_run = max(runs_dir.glob('*'), key=os.path.getmtime)\n","    model_path = latest_run / \"weights\" / \"best.pt\"\n","    if not model_path.exists():\n","        raise FileNotFoundError(f\"Could not find 'best.pt' in the latest run folder: {latest_run}\")\n","\n","    print(f\"🤖 Loading model: {model_path}\")\n","    model = YOLO(model_path)\n","\n","    output_dir = Path.cwd() / \"enhanced_predictions\"; output_dir.mkdir(exist_ok=True)\n","    image_files = [f for f in images_dir.glob('*') if f.suffix.lower() in ['.png', '.jpg', '.jpeg']]\n","\n","    for img_path in tqdm(image_files, desc=\"Predicting on test images\"):\n","        model.predict(img_path, save=True, save_txt=True, project=str(output_dir), name='images', exist_ok=True, verbose=False)\n","\n","    print(f\"✅ Predictions saved to: {output_dir / 'images'}\")\n","    print(\"\\n📊 Running final evaluation on the test set...\")\n","    metrics = model.val(data=str(yaml_path), split=\"test\", device=TRAINING_CONFIG['device'])\n","    print(\"\\n📈 EVALUATION RESULTS:\")\n","    print(f\"   mAP@0.5: {metrics.box.map50:.4f}\")\n","    print(f\"   mAP@0.5:0.95: {metrics.box.map:.4f}\")\n","\n","class EnhancedYoloVisualizer:\n","    MODE_TRAIN, MODE_VAL = 0, 1\n","    def __init__(self, train_root, val_root, class_names):\n","        self.train_root = Path(train_root); self.val_root = Path(val_root)\n","        self.classes = {i: name for i, name in enumerate(class_names)}\n","        self.set_mode(self.MODE_TRAIN)\n","        print(\"🎨 Visualizer Initialized.\")\n","    def set_mode(self, mode):\n","        folder = self.train_root if mode == self.MODE_TRAIN else self.val_root\n","        self.mode_name = \"TRAIN\" if mode == self.MODE_TRAIN else \"VALIDATION\"\n","        self.images_folder = folder / \"images\"; self.labels_folder = folder / \"labels\"\n","        if not self.images_folder.exists(): raise FileNotFoundError(f\"{self.mode_name} images not found at {self.images_folder}\")\n","        self.image_names = sorted([f.name for f in self.images_folder.glob('*')])\n","        self.num_images = len(self.image_names); self.frame_index = 0\n","        print(f\"✅ Mode: {self.mode_name} ({self.num_images} images)\")\n","    def seek_frame(self, idx):\n","        if not (0 <= idx < self.num_images): return None\n","        img_path = self.images_folder / self.image_names[idx]\n","        lbl_path = self.labels_folder / img_path.with_suffix('.txt').name\n","        img = cv2.imread(str(img_path)); h, w = img.shape[:2]\n","        if lbl_path.exists():\n","            with open(lbl_path) as f:\n","                for line in f:\n","                    parts = line.split(); cid, x, y, cw, ch = int(parts[0]), *map(float, parts[1:5])\n","                    x1, y1 = int((x-cw/2)*w), int((y-ch/2)*h)\n","                    x2, y2 = int((x+cw/2)*w), int((y+ch/2)*h)\n","                    cv2.rectangle(img, (x1,y1), (x2,y2), (0,255,0), 2)\n","                    cv2.putText(img, self.classes[cid], (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0,255,0), 2)\n","        return img\n","    def run(self):\n","        print(\"CONTROLS: [A] Prev | [D] Next | [T] Train | [V] Val | [Q] Quit\")\n","        while True:\n","            frame = self.seek_frame(self.frame_index)\n","            # Use a dummy window if running in a non-GUI environment like Colab\n","            try:\n","                cv2.imshow(\"Visualizer\", cv2.resize(frame, (1280, 720)))\n","                key = cv2.waitKey(0) & 0xFF\n","                if key == ord('q'): break\n","                elif key == ord('d'): self.frame_index = (self.frame_index + 1) % self.num_images\n","                elif key == ord('a'): self.frame_index = (self.frame_index - 1 + self.num_images) % self.num_images\n","                elif key == ord('t'): self.set_mode(self.MODE_TRAIN)\n","                elif key == ord('v'): self.set_mode(self.MODE_VAL)\n","            except cv2.error:\n","                print(\"⚠️ Could not display visualizer window. This is expected in environments like base Colab.\")\n","                print(\"Visualization is intended for local execution with a GUI.\")\n","                break\n","        cv2.destroyAllWindows()\n","\n","# =====================================================================================\n","# 🚀 5. MAIN EXECUTION BLOCK\n","# =====================================================================================\n","\n","try:\n","    mode = EXECUTION_CONFIG.get('MODE', 'train').lower()\n","    print(\"=\" * 60)\n","    print(f\"🚀 RUNNING IN MODE: {mode.upper()}\")\n","    print(\"=\" * 60)\n","\n","    if mode == 'train':\n","        train_enhanced_model()\n","    elif mode == 'predict':\n","        run_enhanced_prediction()\n","    elif mode == 'visualize':\n","        train_root = TRAIN_DATA_ROOT / \"train_1\" / \"train1\"\n","        val_root = TRAIN_DATA_ROOT / \"train_1\" / \"val1\"\n","        vis = EnhancedYoloVisualizer(train_root, val_root, CLASS_NAMES)\n","        vis.run()\n","    else:\n","        print(f\"❌ Invalid mode '{mode}'. Please choose 'train', 'predict', or 'visualize'.\")\n","\n","except Exception as e:\n","    import traceback\n","    print(f\"\\n❌ An error occurred: {e}\")\n","    traceback.print_exc()\n","\n","finally:\n","    print(\"\\n🎉 Process finished.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mtM0H0auGbvM","executionInfo":{"status":"ok","timestamp":1758450593849,"user_tz":-330,"elapsed":6860676,"user":{"displayName":"238w1a05e0 DASARI TEJESH","userId":"01113965708764882901"}},"outputId":"5f44c1ee-e89e-480a-d3e6-660cbf8e10ba"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["============================================================\n","🚀 RUNNING IN MODE: TRAIN\n","============================================================\n","✅ Dataset YAML created: /content/yolo_params.yaml\n","🚀 STARTING ENHANCED YOLO TRAINING\n","------------------------------------------------------------\n","🧠 Training with Knowledge Distillation...\n","Ultralytics 8.3.202 🚀 Python-3.12.11 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/yolo_params.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=50, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8s.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=enhanced_safety_detection, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=25, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=runs/detect, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/runs/detect/enhanced_safety_detection, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n","Overriding model.yaml nc=80 with nc=7\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n","  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n","  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n","  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n","  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n","  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n","  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n","  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n"," 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n"," 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n"," 22        [15, 18, 21]  1   2118757  ultralytics.nn.modules.head.Detect           [7, [128, 256, 512]]          \n","Model summary: 129 layers, 11,138,309 parameters, 11,138,293 gradients, 28.7 GFLOPs\n","\n","Transferred 349/355 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 2.1±2.6 ms, read: 209.1±115.2 MB/s, size: 2960.3 KB)\n","\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/MICROSOFT HACK/hackathon2_train_1/train_1/train1/labels.cache... 1767 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 1767/1767 1.7Mit/s 0.0s\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 64.2±140.3 ms, read: 49.2±63.4 MB/s, size: 3185.2 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/MICROSOFT HACK/hackathon2_train_1/train_1/val1/labels... 178 images, 8 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 178/178 3.5it/s 51.1s\n","\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/drive/MyDrive/MICROSOFT HACK/hackathon2_train_1/train_1/val1/labels.cache\n","Plotting labels to /content/runs/detect/enhanced_safety_detection/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.01, momentum=0.937) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 2 dataloader workers\n","Logging results to \u001b[1m/content/runs/detect/enhanced_safety_detection\u001b[0m\n","Starting training for 50 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       1/50      3.93G      1.628      3.084      1.572         37        640: 100% ━━━━━━━━━━━━ 111/111 0.8it/s 2:12\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 6/6 1.0it/s 6.1s\n","                   all        178        460     0.0884      0.155     0.0576     0.0286\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       2/50      3.97G      1.794      2.405      1.717         21        640: 100% ━━━━━━━━━━━━ 111/111 0.9it/s 2:09\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 6/6 2.6it/s 2.3s\n","                   all        178        460      0.328      0.254      0.125      0.062\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       3/50      4.01G      1.793      2.399       1.74         36        640: 100% ━━━━━━━━━━━━ 111/111 0.8it/s 2:11\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 6/6 1.8it/s 3.3s\n","                   all        178        460      0.399      0.188      0.127     0.0594\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       4/50      4.05G      1.701      2.249      1.665         59        640: 100% ━━━━━━━━━━━━ 111/111 0.9it/s 2:10\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 6/6 2.6it/s 2.3s\n","                   all        178        460      0.484      0.292      0.266      0.152\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       5/50      4.08G      1.601      2.082      1.616         37        640: 100% ━━━━━━━━━━━━ 111/111 0.9it/s 2:10\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 6/6 2.4it/s 2.5s\n","                   all        178        460      0.509      0.373      0.306      0.175\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       6/50       4.2G      1.533      1.984      1.578         26        640: 100% ━━━━━━━━━━━━ 111/111 0.9it/s 2:10\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 6/6 2.7it/s 2.2s\n","                   all        178        460      0.439      0.302      0.268      0.157\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       7/50      4.24G      1.469      1.799      1.517         24        640: 100% ━━━━━━━━━━━━ 111/111 0.8it/s 2:12\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 6/6 1.8it/s 3.4s\n","                   all        178        460      0.539      0.328      0.341      0.207\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       8/50      4.28G      1.403      1.715       1.45         32        640: 100% ━━━━━━━━━━━━ 111/111 0.9it/s 2:11\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 6/6 2.5it/s 2.4s\n","                   all        178        460      0.562      0.383      0.414       0.27\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       9/50      4.31G      1.404      1.693      1.459         54        640: 100% ━━━━━━━━━━━━ 111/111 0.9it/s 2:10\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 6/6 1.7it/s 3.5s\n","                   all        178        460      0.651      0.362      0.401      0.235\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      10/50       4.4G      1.346      1.636       1.44         53        640: 100% ━━━━━━━━━━━━ 111/111 0.9it/s 2:10\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 6/6 2.5it/s 2.4s\n","                   all        178        460      0.712      0.371      0.453      0.293\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      11/50       4.5G      1.319      1.598      1.394         25        640: 100% ━━━━━━━━━━━━ 111/111 0.8it/s 2:11\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 6/6 1.8it/s 3.3s\n","                   all        178        460      0.604      0.435      0.482      0.335\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      12/50      4.61G      1.286      1.512      1.374         57        640: 100% ━━━━━━━━━━━━ 111/111 0.8it/s 2:11\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 6/6 2.7it/s 2.2s\n","                   all        178        460      0.638      0.451      0.528      0.369\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      13/50      4.65G      1.219      1.389      1.318         22        640: 100% ━━━━━━━━━━━━ 111/111 0.9it/s 2:10\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 6/6 1.8it/s 3.4s\n","                   all        178        460      0.579      0.451      0.498      0.345\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      14/50      4.87G      1.203      1.393      1.309         24        640: 100% ━━━━━━━━━━━━ 111/111 0.8it/s 2:11\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 6/6 2.4it/s 2.5s\n","                   all        178        460      0.661      0.522      0.561      0.401\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      15/50      4.91G      1.205      1.347      1.307         28        640: 100% ━━━━━━━━━━━━ 111/111 0.9it/s 2:11\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 6/6 2.0it/s 3.0s\n","                   all        178        460       0.62      0.485      0.503      0.338\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      16/50      4.94G      1.201      1.392      1.311         29        640: 100% ━━━━━━━━━━━━ 111/111 0.9it/s 2:10\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 6/6 2.6it/s 2.3s\n","                   all        178        460      0.577      0.497      0.501      0.348\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      17/50      4.98G      1.167      1.322      1.284         66        640: 100% ━━━━━━━━━━━━ 111/111 0.8it/s 2:11\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 6/6 2.3it/s 2.7s\n","                   all        178        460      0.754      0.514      0.569      0.405\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      18/50      5.01G      1.119      1.235      1.262         37        640: 100% ━━━━━━━━━━━━ 111/111 0.9it/s 2:10\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 6/6 2.4it/s 2.5s\n","                   all        178        460      0.772      0.538      0.613      0.449\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      19/50      5.05G       1.09      1.175      1.229         52        640: 100% ━━━━━━━━━━━━ 111/111 0.8it/s 2:12\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 6/6 2.1it/s 2.8s\n","                   all        178        460      0.695      0.523      0.577      0.406\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      20/50      5.17G      1.103      1.192      1.226         28        640: 100% ━━━━━━━━━━━━ 111/111 0.8it/s 2:11\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 6/6 2.6it/s 2.3s\n","                   all        178        460       0.82      0.474      0.615      0.453\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      21/50      5.21G      1.062      1.106      1.212         65        640: 100% ━━━━━━━━━━━━ 111/111 0.8it/s 2:11\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 6/6 1.9it/s 3.1s\n","                   all        178        460       0.81      0.514      0.608      0.444\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      22/50      5.24G       1.04      1.119      1.198         44        640: 100% ━━━━━━━━━━━━ 111/111 0.9it/s 2:10\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 6/6 2.8it/s 2.2s\n","                   all        178        460      0.828      0.509      0.617      0.449\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      23/50      5.28G      1.054      1.106      1.204         29        640: 100% ━━━━━━━━━━━━ 111/111 0.8it/s 2:11\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 6/6 1.8it/s 3.3s\n","                   all        178        460      0.792      0.555      0.636      0.459\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      24/50      5.38G      1.027      1.085      1.197         21        640: 100% ━━━━━━━━━━━━ 111/111 0.8it/s 2:11\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 6/6 2.7it/s 2.2s\n","                   all        178        460      0.741      0.597      0.634      0.455\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      25/50      5.42G      1.014      1.033      1.181         28        640: 100% ━━━━━━━━━━━━ 111/111 0.9it/s 2:10\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 6/6 1.7it/s 3.5s\n","                   all        178        460      0.706      0.597      0.632      0.453\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      26/50      5.45G      1.005      1.045      1.177         59        640: 100% ━━━━━━━━━━━━ 111/111 0.8it/s 2:11\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 6/6 2.6it/s 2.3s\n","                   all        178        460      0.741      0.603      0.655      0.494\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      27/50      5.55G     0.9757     0.9886      1.162         61        640: 100% ━━━━━━━━━━━━ 111/111 0.9it/s 2:09\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 6/6 1.7it/s 3.5s\n","                   all        178        460       0.83      0.583      0.675      0.505\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      28/50      5.59G     0.9585      1.012      1.159         40        640: 100% ━━━━━━━━━━━━ 111/111 0.8it/s 2:11\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 6/6 2.9it/s 2.1s\n","                   all        178        460      0.782      0.595      0.668        0.5\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      29/50      5.63G      0.936     0.9429      1.138         41        640: 100% ━━━━━━━━━━━━ 111/111 0.8it/s 2:11\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 6/6 1.6it/s 3.7s\n","                   all        178        460      0.896      0.579      0.688      0.521\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      30/50      5.78G     0.9504     0.9455      1.143         30        640: 100% ━━━━━━━━━━━━ 111/111 0.9it/s 2:10\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 6/6 2.8it/s 2.1s\n","                   all        178        460      0.773      0.661      0.692      0.507\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      31/50      5.82G     0.9359      0.924      1.136         46        640: 100% ━━━━━━━━━━━━ 111/111 0.9it/s 2:09\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 6/6 2.2it/s 2.7s\n","                   all        178        460      0.785      0.643        0.7      0.526\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      32/50      5.86G     0.9085     0.9075       1.12         30        640: 100% ━━━━━━━━━━━━ 111/111 0.9it/s 2:10\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 6/6 2.6it/s 2.3s\n","                   all        178        460       0.83      0.604      0.693      0.518\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      33/50       5.9G     0.8923     0.8745       1.11         35        640: 100% ━━━━━━━━━━━━ 111/111 0.9it/s 2:08\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 6/6 2.8it/s 2.1s\n","                   all        178        460      0.861      0.599      0.704      0.531\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      34/50      5.98G     0.8717     0.8739        1.1         26        640: 100% ━━━━━━━━━━━━ 111/111 0.8it/s 2:11\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 6/6 2.9it/s 2.1s\n","                   all        178        460      0.838      0.605      0.704      0.522\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      35/50      6.02G     0.8808      0.891      1.101         22        640: 100% ━━━━━━━━━━━━ 111/111 0.8it/s 2:11\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 6/6 2.7it/s 2.3s\n","                   all        178        460      0.802      0.644      0.705      0.535\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      36/50      6.14G     0.8418     0.8344      1.087         25        640: 100% ━━━━━━━━━━━━ 111/111 0.8it/s 2:13\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 6/6 2.5it/s 2.4s\n","                   all        178        460      0.801      0.634       0.69      0.513\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      37/50      6.17G     0.8311     0.8178      1.073         62        640: 100% ━━━━━━━━━━━━ 111/111 0.8it/s 2:12\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 6/6 1.9it/s 3.1s\n","                   all        178        460       0.84      0.628        0.7      0.529\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      38/50      6.27G     0.8374     0.8036      1.077         26        640: 100% ━━━━━━━━━━━━ 111/111 0.8it/s 2:11\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 6/6 2.5it/s 2.4s\n","                   all        178        460      0.885      0.591      0.706      0.545\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      39/50      6.31G     0.8216     0.7735      1.061         37        640: 100% ━━━━━━━━━━━━ 111/111 0.8it/s 2:13\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 6/6 2.6it/s 2.3s\n","                   all        178        460      0.857       0.63      0.711      0.553\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      40/50      6.41G     0.8031     0.7593      1.062         35        640: 100% ━━━━━━━━━━━━ 111/111 0.8it/s 2:11\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 6/6 2.6it/s 2.3s\n","                   all        178        460      0.896        0.6      0.708      0.558\n","Closing dataloader mosaic\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      41/50      6.45G     0.7665     0.7373      1.055         14        640: 100% ━━━━━━━━━━━━ 111/111 0.8it/s 2:12\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 6/6 2.6it/s 2.3s\n","                   all        178        460      0.851      0.585      0.695      0.546\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      42/50      6.47G     0.7409     0.6769      1.037         11        640: 100% ━━━━━━━━━━━━ 111/111 0.8it/s 2:13\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 6/6 3.0it/s 2.0s\n","                   all        178        460      0.837      0.656      0.731      0.564\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      43/50      6.52G     0.7345     0.6809      1.032         22        640: 100% ━━━━━━━━━━━━ 111/111 0.8it/s 2:12\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 6/6 2.1it/s 2.8s\n","                   all        178        460        0.9      0.632       0.72       0.55\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      44/50       6.6G      0.718     0.6359      1.018         28        640: 100% ━━━━━━━━━━━━ 111/111 0.8it/s 2:12\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 6/6 2.5it/s 2.4s\n","                   all        178        460      0.883       0.64      0.729      0.568\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      45/50      6.63G     0.6966     0.6133      1.003         27        640: 100% ━━━━━━━━━━━━ 111/111 0.8it/s 2:11\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 6/6 2.0it/s 2.9s\n","                   all        178        460      0.906      0.597      0.706      0.542\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      46/50      6.97G     0.6874     0.6103      1.003         11        640: 100% ━━━━━━━━━━━━ 111/111 0.8it/s 2:12\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 6/6 2.8it/s 2.1s\n","                   all        178        460      0.855      0.674      0.731      0.566\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      47/50      7.01G     0.6608     0.5811     0.9846         20        640: 100% ━━━━━━━━━━━━ 111/111 0.8it/s 2:12\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 6/6 2.3it/s 2.7s\n","                   all        178        460      0.917      0.606       0.72      0.571\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      48/50      7.04G     0.6562     0.5765     0.9803         37        640: 100% ━━━━━━━━━━━━ 111/111 0.9it/s 2:11\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 6/6 2.7it/s 2.3s\n","                   all        178        460      0.902      0.632      0.727      0.577\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      49/50      7.08G     0.6462     0.5611     0.9732         11        640: 100% ━━━━━━━━━━━━ 111/111 0.8it/s 2:12\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 6/6 2.8it/s 2.1s\n","                   all        178        460      0.888      0.649       0.73      0.582\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      50/50      7.11G     0.6341     0.5387      0.969         14        640: 100% ━━━━━━━━━━━━ 111/111 0.9it/s 2:10\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 6/6 2.5it/s 2.4s\n","                   all        178        460      0.898      0.644      0.736      0.585\n","\n","50 epochs completed in 1.883 hours.\n","Optimizer stripped from /content/runs/detect/enhanced_safety_detection/weights/last.pt, 22.5MB\n","Optimizer stripped from /content/runs/detect/enhanced_safety_detection/weights/best.pt, 22.5MB\n","\n","Validating /content/runs/detect/enhanced_safety_detection/weights/best.pt...\n","Ultralytics 8.3.202 🚀 Python-3.12.11 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n","Model summary (fused): 72 layers, 11,128,293 parameters, 0 gradients, 28.5 GFLOPs\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 6/6 0.8it/s 7.3s\n","                   all        178        460      0.898      0.644      0.736      0.585\n","            OxygenTank         79        118      0.925      0.754      0.839      0.719\n","          NitrogenTank         84        155      0.916       0.69      0.803      0.709\n","           FirstAidBox         30         40      0.843        0.7      0.738      0.621\n","             FireAlarm         25         27      0.937      0.519      0.668      0.529\n","     SafetySwitchPanel         28         30      0.814      0.585      0.675      0.535\n","        EmergencyPhone         34         38      0.858      0.605      0.678      0.388\n","      FireExtinguisher         41         52      0.989      0.654      0.751      0.595\n","Speed: 0.3ms preprocess, 4.2ms inference, 0.0ms loss, 3.8ms postprocess per image\n","Results saved to \u001b[1m/content/runs/detect/enhanced_safety_detection\u001b[0m\n","✅ Training complete!\n","\n","🎉 Process finished.\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"HxZXgd-fG0l-"},"execution_count":null,"outputs":[]}]}